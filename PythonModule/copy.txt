import math as m
class LaplaceUnigramLanguageModel:

  sum_word=""
  word_uni = {}
  def __init__(self, corpus):
    """Initialize your data structures in the constructor."""
    # TODO your code here
    self.train(corpus)

  def train(self, corpus):
    """ Takes a corpus and trains your language model.
        Compute any counts or other corpus statistics in this function.
    """
    # TODO your code here
    for sentence in corpus.corpus: # iterate over sentences in the corpus
      #print(sentence)
      for datum in sentence.data: # iterate over datums in the sentence
        if datum.word not in self.word_uni:
          self.word_uni[datum.word]=1
        else:
          self.word_uni[datum.word]=self.word_uni[datum.word]+1
    # self.word_uni['unk']=0
    # print(sum(self.word_uni.values()))
    # print(self.word_uni['<s>'])
    # print(self.word_uni['<s>']/sum(self.word_uni.values()))

    self.sum_word=sum(self.word_uni.values())+len(self.word_uni)
    pass

  def score(self, sentence):
    """ Takes a list of strings as argument and returns the log-probability of the
        sentence using your language model. Use whatever data you computed in train() here.
    """
    # TODO your code here
    score = 0
    probability = 0
    for token in sentence:  # iterate over words in the sentence
       if token in self.word_uni:

         score+= m.log(self.word_uni[token]+1)
         score-=m.log(self.sum_word)
       else:
         #self.word_uni['unk'] = self.word_uni['unk'] + 1
         score+=m.log(1);
         score-=m.log(self.sum_word)

    return score

import  collections,math
class LaplaceBigramLanguageModel:

  word_uni = collections.defaultdict(list)
  word_bi = collections.defaultdict(list)


  def __init__(self, corpus):
    """Initialize your data structures in the constructor."""
    # TODO your code here
    self.train(corpus)

  def train(self, corpus):
    """ Takes a corpus and trains your language model.
        Compute any counts or other corpus statistics in this function.
    """
    # TODO your code here
    for sentence in corpus.corpus: # iterate over sentences in the corpus
      #print(sentence)
      for datum in range(0,len(sentence.data)-1): # iterate over datums in the sentence
        word_1=sentence.data[datum].word
        word_2=sentence.data[datum+1].word
        if word_1 not in self.word_uni:
          self.word_uni[word_1]=1
        else:
          self.word_uni[word_1]=self.word_uni[word_1]+1

        if word_1+" "+word_2 not in self.word_bi:
          temp=word_1+" "+word_2
          self.word_bi[word_1+" "+word_2].append(1)
          self.word_bi[temp].append(word_1)
        else:
            # print(self.word_bi[word_1+" "+word_2])
            self.word_bi[word_1+" "+word_2][0]=self.word_bi[word_1+" "+word_2][0]+1



        if datum==len(sentence.data)-1:
          word_1 = sentence.data[datum+1].word
          if word_1 not in self.word_uni:
            self.word_uni[word_1] = 1
          else:
            self.word_uni[word_1] = self.word_uni[word_1] + 1

    # self.word_uni['unk']=0
    # print(self.word_uni)
    # print(self.word_bi)

    pass

  def score(self, sentence):
    """ Takes a list of strings as argument and returns the log-probability of the
        sentence using your language model. Use whatever data you computed in train() here.
    """
    score =0;
    # TODO your code here
    for datanum in range(0,len(sentence)-1):
      word_1=sentence[datanum]
      word_2=sentence[datanum+1]
      temp=word_1+" "+word_2
      print(self.word_bi[temp])
      print(self.word_bi[temp][0])
      print(self.word_bi[temp][1])
      if temp in self.word_bi:
        score+=math.log(self.word_bi[temp][0]+1)
        score-=(self.word_uni[self.word_bi[temp][1]]+len(self.word_bi))
      else:
        score += math.log(1)
        score -= (self.word_uni[word_1] + len(self.word_bi))
    return score
import math
import collections
class CustomLanguageModel:
  word_uni = collections.defaultdict(list)
  word_bi = collections.defaultdict(list)

  def __init__(self, corpus):
    """Initialize your data structures in the constructor."""
    # TODO your code here
    self.train(corpus)

  def train(self, corpus):
    """ Takes a corpus and trains your language model.
        Compute any counts or other corpus statistics in this function.
    """
    # TODO your code here
    for sentence in corpus.corpus:  # iterate over sentences in the corpus
      # print(sentence)
      for datum in range(0, len(sentence.data) - 2):  # iterate over datums in the sentence
        word_1 = sentence.data[datum].word+" "+sentence.data[datum+1].word
        word_2 = sentence.data[datum + 2].word
        if word_1 not in self.word_uni:
          self.word_uni[word_1] = 1
        else:
          self.word_uni[word_1] = self.word_uni[word_1] + 1

        if word_1 + " " + word_2 not in self.word_bi:
          temp = word_1 + " " + word_2
          self.word_bi[word_1 + " " + word_2].append(1)
          self.word_bi[temp].append(word_1)
        else:
          # print(self.word_bi[word_1+" "+word_2])
          self.word_bi[word_1 + " " + word_2][0] = self.word_bi[word_1 + " " + word_2][0] + 1


        if datum == len(sentence.data) - 2:
          word_1 = sentence.data[datum + 1].word + " " +sentence.data[datum+2].word
          if word_1 not in self.word_uni:
            self.word_uni[word_1] = 1
          else:
            self.word_uni[word_1] = self.word_uni[word_1] + 1

    # self.word_uni['unk']=0
    # print(self.word_uni)
    # print(self.word_bi)

    pass

  def score(self, sentence):
    """ Takes a list of strings as argument and returns the log-probability of the
        sentence using your language model. Use whatever data you computed in train() here.
    """
    score = 0;
    # TODO your code here
    for datanum in range(0, len(sentence) - 2):
      word_1 = sentence[datanum] +" "+ sentence[datanum +1]
      word_2 = sentence[datanum + 2]

      temp = word_1 + " " + word_2
      print(temp)
      # print(self.word_bi[temp])
      # print(self.word_bi[temp][0])
      # print(self.word_bi[temp][1])
      if temp in self.word_bi:
        score += math.log(self.word_bi[temp][0] + 1)
        score -= (self.word_uni[self.word_bi[temp][1]] + len(self.word_bi))
      else:
        score += math.log(1)
        print(self.word_uni[word_1])
        score -= (self.word_uni[word_1] + len(self.word_bi))
    return score
import  collections,math
class StupidBackoffLanguageModel:

  word_uni = {}
  word_bi = {}
  sum_words=""
  def __init__(self, corpus):
    """Initialize your data structures in the constructor."""
    # TODO your code here
    self.train(corpus)

  def train(self, corpus):
    """ Takes a corpus and trains your language model.
        Compute any counts or other corpus statistics in this function.
    """
    # TODO your code here
    for sentence in corpus.corpus: # iterate over sentences in the corpus
      #print(sentence)
      for datum in range(0,len(sentence.data)-1): # iterate over datums in the sentence
        word_1=sentence.data[datum].word
        word_2=sentence.data[datum+1].word
        if word_1 not in self.word_uni:
          self.word_uni[word_1]=1
        else:
          self.word_uni[word_1]=self.word_uni[word_1]+1

        if word_1+" "+word_2 not in self.word_bi:
          temp=word_1+" "+word_2
          self.word_bi[word_1+" "+word_2].append(1)
          self.word_bi[temp].append(word_1)
        else:
            print(self.word_bi[word_1+" "+word_2])
            self.word_bi[word_1+" "+word_2][0]=self.word_bi[word_1+" "+word_2][0]+1



        if datum==len(sentence.data)-1:
          word_1 = sentence.data[datum+1].word
          if word_1 not in self.word_uni:
            self.word_uni[word_1] = 1
          else:
            self.word_uni[word_1] = self.word_uni[word_1] + 1

    # self.word_uni['unk']=0
    self.sum_words = sum(self.word_uni.values()) + len(self.word_uni)
    # print(self.word_uni)
    # print(self.word_bi)
    pass

  def score(self, sentence):
    """ Takes a list of strings as argument and returns the log-probability of the
        sentence using your language model. Use whatever data you computed in train() here.
    """
    score =0;
    # TODO your code here
    for datanum in range(0,len(sentence)-1):
      word_1=sentence[datanum]
      word_2=sentence[datanum+1]
      temp=word_1+" "+word_2
      if temp in self.word_bi:
        score+=math.log(self.word_bi[temp][0])
        score-=math.log(self.word_uni[self.word_bi[temp][1]])
      else:
        if word_2 in self.word_uni:
          s=((self.word_uni[word_2]+1)/self.sum_words)*0.4
          score+=math.log(s)
          # score-=math.log(self.sum_words)
          # score=score*0.4
        else:
          s = ((1) / self.sum_words)*0.4
          score += math.log(s)
          # score += math.log((1))
          # score -= math.log(self.sum_words)
          # score=score*0.4
    return score
